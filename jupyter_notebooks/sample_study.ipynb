{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import genlogistic\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_data_path = './movie_dataset/release_dates.csv'\n",
    "rdf = pd.read_csv(release_data_path, delimiter=',', header=None)\n",
    "rdf.head()\n",
    "zero_scores = stats.zscore(rdf[2])\n",
    "refined_released_dates = rdf[2][ (np.abs(zero_scores) < 3) ]\n",
    "rrd = refined_released_dates.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "data_directory_prefix = './sequence_data/synthetic_100000'\n",
    "raw_sequences_data_path = data_directory_prefix + '/sequences.shv'\n",
    "\n",
    "d = shelve.open('./test111.shv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "a.append(123)\n",
    "d['123'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package diskcache:\n",
      "\n",
      "NAME\n",
      "    diskcache\n",
      "\n",
      "DESCRIPTION\n",
      "    DiskCache API Reference\n",
      "    =======================\n",
      "    \n",
      "    The :doc:`tutorial` provides a helpful walkthrough of most methods.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    cli\n",
      "    core\n",
      "    djangocache\n",
      "    fanout\n",
      "    persistent\n",
      "    recipes\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        diskcache.core.Timeout\n",
      "    builtins.UserWarning(builtins.Warning)\n",
      "        diskcache.core.EmptyDirWarning\n",
      "        diskcache.core.UnknownFileWarning\n",
      "    builtins.object\n",
      "        diskcache.core.Cache\n",
      "        diskcache.core.Disk\n",
      "            diskcache.core.JSONDisk\n",
      "        diskcache.fanout.FanoutCache\n",
      "        diskcache.recipes.Averager\n",
      "        diskcache.recipes.BoundedSemaphore\n",
      "        diskcache.recipes.Lock\n",
      "        diskcache.recipes.RLock\n",
      "    collections.abc.MutableMapping(collections.abc.Mapping)\n",
      "        diskcache.persistent.Index\n",
      "    collections.abc.Sequence(collections.abc.Reversible, collections.abc.Collection)\n",
      "        diskcache.persistent.Deque\n",
      "    \n",
      "    class Averager(builtins.object)\n",
      "     |  Averager(cache, key, expire=None, tag=None)\n",
      "     |  \n",
      "     |  Recipe for calculating a running average.\n",
      "     |  \n",
      "     |  Sometimes known as \"online statistics,\" the running average maintains the\n",
      "     |  total and count. The average can then be calculated at any time.\n",
      "     |  \n",
      "     |  >>> import diskcache\n",
      "     |  >>> cache = diskcache.FanoutCache()\n",
      "     |  >>> ave = Averager(cache, 'latency')\n",
      "     |  >>> ave.add(0.080)\n",
      "     |  >>> ave.add(0.120)\n",
      "     |  >>> ave.get()\n",
      "     |  0.1\n",
      "     |  >>> ave.add(0.160)\n",
      "     |  >>> ave.pop()\n",
      "     |  0.12\n",
      "     |  >>> print(ave.get())\n",
      "     |  None\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, cache, key, expire=None, tag=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  add(self, value)\n",
      "     |      Add `value` to average.\n",
      "     |  \n",
      "     |  get(self)\n",
      "     |      Get current average or return `None` if count equals zero.\n",
      "     |  \n",
      "     |  pop(self)\n",
      "     |      Return current average and delete key.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class BoundedSemaphore(builtins.object)\n",
      "     |  BoundedSemaphore(cache, key, value=1, expire=None, tag=None)\n",
      "     |  \n",
      "     |  Recipe for cross-process and cross-thread bounded semaphore.\n",
      "     |  \n",
      "     |  >>> import diskcache\n",
      "     |  >>> cache = diskcache.Cache()\n",
      "     |  >>> semaphore = BoundedSemaphore(cache, 'max-cons', value=2)\n",
      "     |  >>> semaphore.acquire()\n",
      "     |  >>> semaphore.acquire()\n",
      "     |  >>> semaphore.release()\n",
      "     |  >>> with semaphore:\n",
      "     |  ...     pass\n",
      "     |  >>> semaphore.release()\n",
      "     |  >>> semaphore.release()\n",
      "     |  Traceback (most recent call last):\n",
      "     |    ...\n",
      "     |  AssertionError: cannot release un-acquired semaphore\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *exc_info)\n",
      "     |  \n",
      "     |  __init__(self, cache, key, value=1, expire=None, tag=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  acquire(self)\n",
      "     |      Acquire semaphore by decrementing value using spin-lock algorithm.\n",
      "     |  \n",
      "     |  release(self)\n",
      "     |      Release semaphore by incrementing value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Cache(builtins.object)\n",
      "     |  Cache(directory=None, timeout=60, disk=<class 'diskcache.core.Disk'>, **settings)\n",
      "     |  \n",
      "     |  Disk and file backed cache.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      Return `True` if `key` matching item is found in cache.\n",
      "     |      \n",
      "     |      :param key: key matching item\n",
      "     |      :return: True if key matching item\n",
      "     |  \n",
      "     |  __delitem__(self, key, retry=True)\n",
      "     |      Delete corresponding item for `key` from cache.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default `True`).\n",
      "     |      \n",
      "     |      :param key: key matching item\n",
      "     |      :param bool retry: retry if database timeout occurs (default True)\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *exception)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Return corresponding value for `key` from cache.\n",
      "     |      \n",
      "     |      :param key: key matching item\n",
      "     |      :return: corresponding value\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, directory=None, timeout=60, disk=<class 'diskcache.core.Disk'>, **settings)\n",
      "     |      Initialize cache instance.\n",
      "     |      \n",
      "     |      :param str directory: cache directory\n",
      "     |      :param float timeout: SQLite connection timeout\n",
      "     |      :param disk: Disk type or subclass for serialization\n",
      "     |      :param settings: any of DEFAULT_SETTINGS\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterate keys in cache including expired items.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Count of items in cache including expired items.\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverse iterate keys in cache including expired items.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Set corresponding `value` for `key` in cache.\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param value: value for item\n",
      "     |      :return: corresponding value\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  add(self, key, value, expire=None, read=False, tag=None, retry=False)\n",
      "     |      Add `key` and `value` item to cache.\n",
      "     |      \n",
      "     |      Similar to `set`, but only add to cache if key not present.\n",
      "     |      \n",
      "     |      Operation is atomic. Only one concurrent add operation for a given key\n",
      "     |      will succeed.\n",
      "     |      \n",
      "     |      When `read` is `True`, `value` should be a file-like object opened\n",
      "     |      for reading in binary mode.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param value: value for item\n",
      "     |      :param float expire: seconds until the key expires\n",
      "     |          (default None, no expiry)\n",
      "     |      :param bool read: read value as bytes from file (default False)\n",
      "     |      :param str tag: text to associate with key (default None)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if item was added\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  check(self, fix=False, retry=False)\n",
      "     |      Check database and file system consistency.\n",
      "     |      \n",
      "     |      Intended for use in testing and post-mortem error analysis.\n",
      "     |      \n",
      "     |      While checking the Cache table for consistency, a writer lock is held\n",
      "     |      on the database. The lock blocks other cache clients from writing to\n",
      "     |      the database. For caches with many file references, the lock may be\n",
      "     |      held for a long time. For example, local benchmarking shows that a\n",
      "     |      cache with 1,000 file references takes ~60ms to check.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param bool fix: correct inconsistencies\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: list of warnings\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  clear(self, retry=False)\n",
      "     |      Remove all items from cache.\n",
      "     |      \n",
      "     |      Removing items is an iterative process. In each iteration, a subset of\n",
      "     |      items is removed. Concurrent writes may occur between iterations.\n",
      "     |      \n",
      "     |      If a :exc:`Timeout` occurs, the first element of the exception's\n",
      "     |      `args` attribute will be the number of items removed before the\n",
      "     |      exception occurred.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of rows removed\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close database connection.\n",
      "     |  \n",
      "     |  create_tag_index(self)\n",
      "     |      Create tag index on cache database.\n",
      "     |      \n",
      "     |      It is better to initialize cache with `tag_index=True` than use this.\n",
      "     |      \n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  cull(self, retry=False)\n",
      "     |      Cull items from cache until volume is less than size limit.\n",
      "     |      \n",
      "     |      Removing items is an iterative process. In each iteration, a subset of\n",
      "     |      items is removed. Concurrent writes may occur between iterations.\n",
      "     |      \n",
      "     |      If a :exc:`Timeout` occurs, the first element of the exception's\n",
      "     |      `args` attribute will be the number of items removed before the\n",
      "     |      exception occurred.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of items removed\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  decr(self, key, delta=1, default=0, retry=False)\n",
      "     |      Decrement value by delta for item with key.\n",
      "     |      \n",
      "     |      If key is missing and default is None then raise KeyError. Else if key\n",
      "     |      is missing and default is not None then use default for value.\n",
      "     |      \n",
      "     |      Operation is atomic. All concurrent decrement operations will be\n",
      "     |      counted individually.\n",
      "     |      \n",
      "     |      Unlike Memcached, negative values are supported. Value may be\n",
      "     |      decremented below zero.\n",
      "     |      \n",
      "     |      Assumes value may be stored in a SQLite column. Most builds that target\n",
      "     |      machines with 64-bit pointer widths will support 64-bit signed\n",
      "     |      integers.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param int delta: amount to decrement (default 1)\n",
      "     |      :param int default: value if key is missing (default 0)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: new value for item\n",
      "     |      :raises KeyError: if key is not found and default is None\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  delete(self, key, retry=False)\n",
      "     |      Delete corresponding item for `key` from cache.\n",
      "     |      \n",
      "     |      Missing keys are ignored.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key matching item\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if item was deleted\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  drop_tag_index(self)\n",
      "     |      Drop tag index on cache database.\n",
      "     |      \n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  evict(self, tag, retry=False)\n",
      "     |      Remove items with matching `tag` from cache.\n",
      "     |      \n",
      "     |      Removing items is an iterative process. In each iteration, a subset of\n",
      "     |      items is removed. Concurrent writes may occur between iterations.\n",
      "     |      \n",
      "     |      If a :exc:`Timeout` occurs, the first element of the exception's\n",
      "     |      `args` attribute will be the number of items removed before the\n",
      "     |      exception occurred.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param str tag: tag identifying items\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of rows removed\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  expire(self, now=None, retry=False)\n",
      "     |      Remove expired items from cache.\n",
      "     |      \n",
      "     |      Removing items is an iterative process. In each iteration, a subset of\n",
      "     |      items is removed. Concurrent writes may occur between iterations.\n",
      "     |      \n",
      "     |      If a :exc:`Timeout` occurs, the first element of the exception's\n",
      "     |      `args` attribute will be the number of items removed before the\n",
      "     |      exception occurred.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param float now: current time (default None, ``time.time()`` used)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of items removed\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  get(self, key, default=None, read=False, expire_time=False, tag=False, retry=False)\n",
      "     |      Retrieve value from cache. If `key` is missing, return `default`.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param default: value to return if key is missing (default None)\n",
      "     |      :param bool read: if True, return file handle to value\n",
      "     |          (default False)\n",
      "     |      :param bool expire_time: if True, return expire_time in tuple\n",
      "     |          (default False)\n",
      "     |      :param bool tag: if True, return tag in tuple (default False)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: value for item or default if key not found\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  incr(self, key, delta=1, default=0, retry=False)\n",
      "     |      Increment value by delta for item with key.\n",
      "     |      \n",
      "     |      If key is missing and default is None then raise KeyError. Else if key\n",
      "     |      is missing and default is not None then use default for value.\n",
      "     |      \n",
      "     |      Operation is atomic. All concurrent increment operations will be\n",
      "     |      counted individually.\n",
      "     |      \n",
      "     |      Assumes value may be stored in a SQLite column. Most builds that target\n",
      "     |      machines with 64-bit pointer widths will support 64-bit signed\n",
      "     |      integers.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param int delta: amount to increment (default 1)\n",
      "     |      :param int default: value if key is missing (default 0)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: new value for item\n",
      "     |      :raises KeyError: if key is not found and default is None\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  iterkeys(self, reverse=False)\n",
      "     |      Iterate Cache keys in database sort order.\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> for key in [4, 1, 3, 0, 2]:\n",
      "     |      ...     cache[key] = key\n",
      "     |      >>> list(cache.iterkeys())\n",
      "     |      [0, 1, 2, 3, 4]\n",
      "     |      >>> list(cache.iterkeys(reverse=True))\n",
      "     |      [4, 3, 2, 1, 0]\n",
      "     |      \n",
      "     |      :param bool reverse: reverse sort order (default False)\n",
      "     |      :return: iterator of Cache keys\n",
      "     |  \n",
      "     |  memoize(self, name=None, typed=False, expire=None, tag=None)\n",
      "     |      Memoizing cache decorator.\n",
      "     |      \n",
      "     |      Decorator to wrap callable with memoizing function using cache.\n",
      "     |      Repeated calls with the same arguments will lookup result in cache and\n",
      "     |      avoid function evaluation.\n",
      "     |      \n",
      "     |      If name is set to None (default), the callable name will be determined\n",
      "     |      automatically.\n",
      "     |      \n",
      "     |      When expire is set to zero, function results will not be set in the\n",
      "     |      cache. Cache lookups still occur, however. Read\n",
      "     |      :doc:`case-study-landing-page-caching` for example usage.\n",
      "     |      \n",
      "     |      If typed is set to True, function arguments of different types will be\n",
      "     |      cached separately. For example, f(3) and f(3.0) will be treated as\n",
      "     |      distinct calls with distinct results.\n",
      "     |      \n",
      "     |      The original underlying function is accessible through the __wrapped__\n",
      "     |      attribute. This is useful for introspection, for bypassing the cache,\n",
      "     |      or for rewrapping the function with a different cache.\n",
      "     |      \n",
      "     |      >>> from diskcache import Cache\n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> @cache.memoize(expire=1, tag='fib')\n",
      "     |      ... def fibonacci(number):\n",
      "     |      ...     if number == 0:\n",
      "     |      ...         return 0\n",
      "     |      ...     elif number == 1:\n",
      "     |      ...         return 1\n",
      "     |      ...     else:\n",
      "     |      ...         return fibonacci(number - 1) + fibonacci(number - 2)\n",
      "     |      >>> print(fibonacci(100))\n",
      "     |      354224848179261915075\n",
      "     |      \n",
      "     |      An additional `__cache_key__` attribute can be used to generate the\n",
      "     |      cache key used for the given arguments.\n",
      "     |      \n",
      "     |      >>> key = fibonacci.__cache_key__(100)\n",
      "     |      >>> print(cache[key])\n",
      "     |      354224848179261915075\n",
      "     |      \n",
      "     |      Remember to call memoize when decorating a callable. If you forget,\n",
      "     |      then a TypeError will occur. Note the lack of parenthenses after\n",
      "     |      memoize below:\n",
      "     |      \n",
      "     |      >>> @cache.memoize\n",
      "     |      ... def test():\n",
      "     |      ...     pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      TypeError: name cannot be callable\n",
      "     |      \n",
      "     |      :param cache: cache to store callable arguments and return values\n",
      "     |      :param str name: name given for callable (default None, automatic)\n",
      "     |      :param bool typed: cache different types separately (default False)\n",
      "     |      :param float expire: seconds until arguments expire\n",
      "     |          (default None, no expiry)\n",
      "     |      :param str tag: text to associate with arguments (default None)\n",
      "     |      :return: callable decorator\n",
      "     |  \n",
      "     |  peek(self, prefix=None, default=(None, None), side='front', expire_time=False, tag=False, retry=False)\n",
      "     |      Peek at key and value item pair from `side` of queue in cache.\n",
      "     |      \n",
      "     |      When prefix is None, integer keys are used. Otherwise, string keys are\n",
      "     |      used in the format \"prefix-integer\". Integer starts at 500 trillion.\n",
      "     |      \n",
      "     |      If queue is empty, return default.\n",
      "     |      \n",
      "     |      Defaults to peeking at key and value item pairs from front of queue.\n",
      "     |      Set side to 'back' to pull from back of queue. Side must be one of\n",
      "     |      'front' or 'back'.\n",
      "     |      \n",
      "     |      Expired items are deleted from cache. Operation is atomic. Concurrent\n",
      "     |      operations will be serialized.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      See also `Cache.pull` and `Cache.push`.\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> for letter in 'abc':\n",
      "     |      ...     print(cache.push(letter))\n",
      "     |      500000000000000\n",
      "     |      500000000000001\n",
      "     |      500000000000002\n",
      "     |      >>> key, value = cache.peek()\n",
      "     |      >>> print(key)\n",
      "     |      500000000000000\n",
      "     |      >>> value\n",
      "     |      'a'\n",
      "     |      >>> key, value = cache.peek(side='back')\n",
      "     |      >>> print(key)\n",
      "     |      500000000000002\n",
      "     |      >>> value\n",
      "     |      'c'\n",
      "     |      \n",
      "     |      :param str prefix: key prefix (default None, key is integer)\n",
      "     |      :param default: value to return if key is missing\n",
      "     |          (default (None, None))\n",
      "     |      :param str side: either 'front' or 'back' (default 'front')\n",
      "     |      :param bool expire_time: if True, return expire_time in tuple\n",
      "     |          (default False)\n",
      "     |      :param bool tag: if True, return tag in tuple (default False)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: key and value item pair or default if queue is empty\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  peekitem(self, last=True, expire_time=False, tag=False, retry=False)\n",
      "     |      Peek at key and value item pair in cache based on iteration order.\n",
      "     |      \n",
      "     |      Expired items are deleted from cache. Operation is atomic. Concurrent\n",
      "     |      operations will be serialized.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> for num, letter in enumerate('abc'):\n",
      "     |      ...     cache[letter] = num\n",
      "     |      >>> cache.peekitem()\n",
      "     |      ('c', 2)\n",
      "     |      >>> cache.peekitem(last=False)\n",
      "     |      ('a', 0)\n",
      "     |      \n",
      "     |      :param bool last: last item in iteration order (default True)\n",
      "     |      :param bool expire_time: if True, return expire_time in tuple\n",
      "     |          (default False)\n",
      "     |      :param bool tag: if True, return tag in tuple (default False)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: key and value item pair\n",
      "     |      :raises KeyError: if cache is empty\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  pop(self, key, default=None, expire_time=False, tag=False, retry=False)\n",
      "     |      Remove corresponding item for `key` from cache and return value.\n",
      "     |      \n",
      "     |      If `key` is missing, return `default`.\n",
      "     |      \n",
      "     |      Operation is atomic. Concurrent operations will be serialized.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param default: value to return if key is missing (default None)\n",
      "     |      :param bool expire_time: if True, return expire_time in tuple\n",
      "     |          (default False)\n",
      "     |      :param bool tag: if True, return tag in tuple (default False)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: value for item or default if key not found\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  pull(self, prefix=None, default=(None, None), side='front', expire_time=False, tag=False, retry=False)\n",
      "     |      Pull key and value item pair from `side` of queue in cache.\n",
      "     |      \n",
      "     |      When prefix is None, integer keys are used. Otherwise, string keys are\n",
      "     |      used in the format \"prefix-integer\". Integer starts at 500 trillion.\n",
      "     |      \n",
      "     |      If queue is empty, return default.\n",
      "     |      \n",
      "     |      Defaults to pulling key and value item pairs from front of queue. Set\n",
      "     |      side to 'back' to pull from back of queue. Side must be one of 'front'\n",
      "     |      or 'back'.\n",
      "     |      \n",
      "     |      Operation is atomic. Concurrent operations will be serialized.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      See also `Cache.push` and `Cache.get`.\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> cache.pull()\n",
      "     |      (None, None)\n",
      "     |      >>> for letter in 'abc':\n",
      "     |      ...     print(cache.push(letter))\n",
      "     |      500000000000000\n",
      "     |      500000000000001\n",
      "     |      500000000000002\n",
      "     |      >>> key, value = cache.pull()\n",
      "     |      >>> print(key)\n",
      "     |      500000000000000\n",
      "     |      >>> value\n",
      "     |      'a'\n",
      "     |      >>> _, value = cache.pull(side='back')\n",
      "     |      >>> value\n",
      "     |      'c'\n",
      "     |      >>> cache.push(1234, 'userids')\n",
      "     |      'userids-500000000000000'\n",
      "     |      >>> _, value = cache.pull('userids')\n",
      "     |      >>> value\n",
      "     |      1234\n",
      "     |      \n",
      "     |      :param str prefix: key prefix (default None, key is integer)\n",
      "     |      :param default: value to return if key is missing\n",
      "     |          (default (None, None))\n",
      "     |      :param str side: either 'front' or 'back' (default 'front')\n",
      "     |      :param bool expire_time: if True, return expire_time in tuple\n",
      "     |          (default False)\n",
      "     |      :param bool tag: if True, return tag in tuple (default False)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: key and value item pair or default if queue is empty\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  push(self, value, prefix=None, side='back', expire=None, read=False, tag=None, retry=False)\n",
      "     |      Push `value` onto `side` of queue identified by `prefix` in cache.\n",
      "     |      \n",
      "     |      When prefix is None, integer keys are used. Otherwise, string keys are\n",
      "     |      used in the format \"prefix-integer\". Integer starts at 500 trillion.\n",
      "     |      \n",
      "     |      Defaults to pushing value on back of queue. Set side to 'front' to push\n",
      "     |      value on front of queue. Side must be one of 'back' or 'front'.\n",
      "     |      \n",
      "     |      Operation is atomic. Concurrent operations will be serialized.\n",
      "     |      \n",
      "     |      When `read` is `True`, `value` should be a file-like object opened\n",
      "     |      for reading in binary mode.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      See also `Cache.pull`.\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> print(cache.push('first value'))\n",
      "     |      500000000000000\n",
      "     |      >>> cache.get(500000000000000)\n",
      "     |      'first value'\n",
      "     |      >>> print(cache.push('second value'))\n",
      "     |      500000000000001\n",
      "     |      >>> print(cache.push('third value', side='front'))\n",
      "     |      499999999999999\n",
      "     |      >>> cache.push(1234, prefix='userids')\n",
      "     |      'userids-500000000000000'\n",
      "     |      \n",
      "     |      :param value: value for item\n",
      "     |      :param str prefix: key prefix (default None, key is integer)\n",
      "     |      :param str side: either 'back' or 'front' (default 'back')\n",
      "     |      :param float expire: seconds until the key expires\n",
      "     |          (default None, no expiry)\n",
      "     |      :param bool read: read value as bytes from file (default False)\n",
      "     |      :param str tag: text to associate with key (default None)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: key for item in cache\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  read(self, key, retry=False)\n",
      "     |      Return file handle value corresponding to `key` from cache.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key matching item\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: file open for reading in binary mode\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  reset(self, key, value=ENOVAL, update=True)\n",
      "     |      Reset `key` and `value` item from Settings table.\n",
      "     |      \n",
      "     |      Use `reset` to update the value of Cache settings correctly. Cache\n",
      "     |      settings are stored in the Settings table of the SQLite database. If\n",
      "     |      `update` is ``False`` then no attempt is made to update the database.\n",
      "     |      \n",
      "     |      If `value` is not given, it is reloaded from the Settings\n",
      "     |      table. Otherwise, the Settings table is updated.\n",
      "     |      \n",
      "     |      Settings with the ``disk_`` prefix correspond to Disk\n",
      "     |      attributes. Updating the value will change the unprefixed attribute on\n",
      "     |      the associated Disk instance.\n",
      "     |      \n",
      "     |      Settings with the ``sqlite_`` prefix correspond to SQLite\n",
      "     |      pragmas. Updating the value will execute the corresponding PRAGMA\n",
      "     |      statement.\n",
      "     |      \n",
      "     |      SQLite PRAGMA statements may be executed before the Settings table\n",
      "     |      exists in the database by setting `update` to ``False``.\n",
      "     |      \n",
      "     |      :param str key: Settings key for item\n",
      "     |      :param value: value for item (optional)\n",
      "     |      :param bool update: update database Settings table (default True)\n",
      "     |      :return: updated value for item\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  set(self, key, value, expire=None, read=False, tag=None, retry=False)\n",
      "     |      Set `key` and `value` item in cache.\n",
      "     |      \n",
      "     |      When `read` is `True`, `value` should be a file-like object opened\n",
      "     |      for reading in binary mode.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param value: value for item\n",
      "     |      :param float expire: seconds until item expires\n",
      "     |          (default None, no expiry)\n",
      "     |      :param bool read: read value as bytes from file (default False)\n",
      "     |      :param str tag: text to associate with key (default None)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if item was set\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  stats(self, enable=True, reset=False)\n",
      "     |      Return cache statistics hits and misses.\n",
      "     |      \n",
      "     |      :param bool enable: enable collecting statistics (default True)\n",
      "     |      :param bool reset: reset hits and misses to 0 (default False)\n",
      "     |      :return: (hits, misses)\n",
      "     |  \n",
      "     |  touch(self, key, expire=None, retry=False)\n",
      "     |      Touch `key` in cache and update `expire` time.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param float expire: seconds until item expires\n",
      "     |          (default None, no expiry)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if key was touched\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  transact(self, retry=False)\n",
      "     |      Context manager to perform a transaction by locking the cache.\n",
      "     |      \n",
      "     |      While the cache is locked, no other write operation is permitted.\n",
      "     |      Transactions should therefore be as short as possible. Read and write\n",
      "     |      operations performed in a transaction are atomic. Read operations may\n",
      "     |      occur concurrent to a transaction.\n",
      "     |      \n",
      "     |      Transactions may be nested and may not be shared between threads.\n",
      "     |      \n",
      "     |      Raises :exc:`Timeout` error when database timeout occurs and `retry` is\n",
      "     |      `False` (default).\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> with cache.transact():  # Atomically increment two keys.\n",
      "     |      ...     _ = cache.incr('total', 123.4)\n",
      "     |      ...     _ = cache.incr('count', 1)\n",
      "     |      >>> with cache.transact():  # Atomically calculate average.\n",
      "     |      ...     average = cache['total'] / cache['count']\n",
      "     |      >>> average\n",
      "     |      123.4\n",
      "     |      \n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: context manager for use in `with` statement\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  volume(self)\n",
      "     |      Return estimated total size of cache on disk.\n",
      "     |      \n",
      "     |      :return: size in bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  directory\n",
      "     |      Cache directory.\n",
      "     |  \n",
      "     |  disk\n",
      "     |      Disk used for serialization.\n",
      "     |  \n",
      "     |  timeout\n",
      "     |      SQLite connection timeout value in seconds.\n",
      "    \n",
      "    class Deque(collections.abc.Sequence)\n",
      "     |  Deque(iterable=(), directory=None)\n",
      "     |  \n",
      "     |  Persistent sequence with double-ended queue semantics.\n",
      "     |  \n",
      "     |  Double-ended queue is an ordered collection with optimized access at its\n",
      "     |  endpoints.\n",
      "     |  \n",
      "     |  Items are serialized to disk. Deque may be initialized from directory path\n",
      "     |  where items are stored.\n",
      "     |  \n",
      "     |  >>> deque = Deque()\n",
      "     |  >>> deque += range(5)\n",
      "     |  >>> list(deque)\n",
      "     |  [0, 1, 2, 3, 4]\n",
      "     |  >>> for value in range(5):\n",
      "     |  ...     deque.appendleft(-value)\n",
      "     |  >>> len(deque)\n",
      "     |  10\n",
      "     |  >>> list(deque)\n",
      "     |  [-4, -3, -2, -1, 0, 0, 1, 2, 3, 4]\n",
      "     |  >>> deque.pop()\n",
      "     |  4\n",
      "     |  >>> deque.popleft()\n",
      "     |  -4\n",
      "     |  >>> deque.reverse()\n",
      "     |  >>> list(deque)\n",
      "     |  [3, 2, 1, 0, 0, -1, -2, -3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Deque\n",
      "     |      collections.abc.Sequence\n",
      "     |      collections.abc.Reversible\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __delitem__(self, index)\n",
      "     |      deque.__delitem__(index) <==> del deque[index]\n",
      "     |      \n",
      "     |      Delete item in deque at `index`.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.extend([None] * 3)\n",
      "     |      >>> del deque[0]\n",
      "     |      >>> del deque[1]\n",
      "     |      >>> del deque[-1]\n",
      "     |      >>> len(deque)\n",
      "     |      0\n",
      "     |      \n",
      "     |      :param int index: index of item\n",
      "     |      :raises IndexError: if index out of range\n",
      "     |  \n",
      "     |  __eq__(self, that)\n",
      "     |      Return True if and only if deque is equal to `that`.\n",
      "     |  \n",
      "     |  __ge__(self, that)\n",
      "     |      Return True if and only if deque is greater than or equal to `that`.\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      deque.__getitem__(index) <==> deque[index]\n",
      "     |      \n",
      "     |      Return corresponding item for `index` in deque.\n",
      "     |      \n",
      "     |      See also `Deque.peekleft` and `Deque.peek` for indexing deque at index\n",
      "     |      ``0`` or ``-1``.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.extend('abcde')\n",
      "     |      >>> deque[1]\n",
      "     |      'b'\n",
      "     |      >>> deque[-2]\n",
      "     |      'd'\n",
      "     |      \n",
      "     |      :param int index: index of item\n",
      "     |      :return: corresponding item\n",
      "     |      :raises IndexError: if index out of range\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __gt__(self, that)\n",
      "     |      Return True if and only if deque is greater than `that`.\n",
      "     |  \n",
      "     |  __iadd__(self, iterable)\n",
      "     |      deque.__iadd__(iterable) <==> deque += iterable\n",
      "     |      \n",
      "     |      Extend back side of deque with items from iterable.\n",
      "     |      \n",
      "     |      :param iterable: iterable of items to append to deque\n",
      "     |      :return: deque with added items\n",
      "     |  \n",
      "     |  __init__(self, iterable=(), directory=None)\n",
      "     |      Initialize deque instance.\n",
      "     |      \n",
      "     |      If directory is None then temporary directory created. The directory\n",
      "     |      will *not* be automatically removed.\n",
      "     |      \n",
      "     |      :param iterable: iterable of items to append to deque\n",
      "     |      :param directory: deque directory (default None)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      deque.__iter__() <==> iter(deque)\n",
      "     |      \n",
      "     |      Return iterator of deque from front to back.\n",
      "     |  \n",
      "     |  __le__(self, that)\n",
      "     |      Return True if and only if deque is less than or equal to `that`.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      deque.__len__() <==> len(deque)\n",
      "     |      \n",
      "     |      Return length of deque.\n",
      "     |  \n",
      "     |  __lt__(self, that)\n",
      "     |      Return True if and only if deque is less than `that`.\n",
      "     |  \n",
      "     |  __ne__(self, that)\n",
      "     |      Return True if and only if deque is not equal to `that`.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      deque.__repr__() <==> repr(deque)\n",
      "     |      \n",
      "     |      Return string with printable representation of deque.\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      deque.__reversed__() <==> reversed(deque)\n",
      "     |      \n",
      "     |      Return iterator of deque from back to front.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.extend('abcd')\n",
      "     |      >>> iterator = reversed(deque)\n",
      "     |      >>> next(iterator)\n",
      "     |      'd'\n",
      "     |      >>> list(iterator)\n",
      "     |      ['c', 'b', 'a']\n",
      "     |  \n",
      "     |  __setitem__(self, index, value)\n",
      "     |      deque.__setitem__(index, value) <==> deque[index] = value\n",
      "     |      \n",
      "     |      Store `value` in deque at `index`.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.extend([None] * 3)\n",
      "     |      >>> deque[0] = 'a'\n",
      "     |      >>> deque[1] = 'b'\n",
      "     |      >>> deque[-1] = 'c'\n",
      "     |      >>> ''.join(deque)\n",
      "     |      'abc'\n",
      "     |      \n",
      "     |      :param int index: index of value\n",
      "     |      :param value: value to store\n",
      "     |      :raises IndexError: if index out of range\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  append(self, value)\n",
      "     |      Add `value` to back of deque.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.append('a')\n",
      "     |      >>> deque.append('b')\n",
      "     |      >>> deque.append('c')\n",
      "     |      >>> list(deque)\n",
      "     |      ['a', 'b', 'c']\n",
      "     |      \n",
      "     |      :param value: value to add to back of deque\n",
      "     |  \n",
      "     |  appendleft(self, value)\n",
      "     |      Add `value` to front of deque.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.appendleft('a')\n",
      "     |      >>> deque.appendleft('b')\n",
      "     |      >>> deque.appendleft('c')\n",
      "     |      >>> list(deque)\n",
      "     |      ['c', 'b', 'a']\n",
      "     |      \n",
      "     |      :param value: value to add to front of deque\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      Remove all elements from deque.\n",
      "     |      \n",
      "     |      >>> deque = Deque('abc')\n",
      "     |      >>> len(deque)\n",
      "     |      3\n",
      "     |      >>> deque.clear()\n",
      "     |      >>> list(deque)\n",
      "     |      []\n",
      "     |  \n",
      "     |  count(self, value)\n",
      "     |      Return number of occurrences of `value` in deque.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque += [num for num in range(1, 5) for _ in range(num)]\n",
      "     |      >>> deque.count(0)\n",
      "     |      0\n",
      "     |      >>> deque.count(1)\n",
      "     |      1\n",
      "     |      >>> deque.count(4)\n",
      "     |      4\n",
      "     |      \n",
      "     |      :param value: value to count in deque\n",
      "     |      :return: count of items equal to value in deque\n",
      "     |  \n",
      "     |  extend(self, iterable)\n",
      "     |      Extend back side of deque with values from `iterable`.\n",
      "     |      \n",
      "     |      :param iterable: iterable of values\n",
      "     |  \n",
      "     |  extendleft(self, iterable)\n",
      "     |      Extend front side of deque with value from `iterable`.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.extendleft('abc')\n",
      "     |      >>> list(deque)\n",
      "     |      ['c', 'b', 'a']\n",
      "     |      \n",
      "     |      :param iterable: iterable of values\n",
      "     |  \n",
      "     |  peek(self)\n",
      "     |      Peek at value at back of deque.\n",
      "     |      \n",
      "     |      Faster than indexing deque at -1.\n",
      "     |      \n",
      "     |      If deque is empty then raise IndexError.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.peek()\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      IndexError: peek from an empty deque\n",
      "     |      >>> deque += 'abc'\n",
      "     |      >>> deque.peek()\n",
      "     |      'c'\n",
      "     |      \n",
      "     |      :return: value at back of deque\n",
      "     |      :raises IndexError: if deque is empty\n",
      "     |  \n",
      "     |  peekleft(self)\n",
      "     |      Peek at value at back of deque.\n",
      "     |      \n",
      "     |      Faster than indexing deque at 0.\n",
      "     |      \n",
      "     |      If deque is empty then raise IndexError.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque.peekleft()\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      IndexError: peek from an empty deque\n",
      "     |      >>> deque += 'abc'\n",
      "     |      >>> deque.peekleft()\n",
      "     |      'a'\n",
      "     |      \n",
      "     |      :return: value at front of deque\n",
      "     |      :raises IndexError: if deque is empty\n",
      "     |  \n",
      "     |  pop(self)\n",
      "     |      Remove and return value at back of deque.\n",
      "     |      \n",
      "     |      If deque is empty then raise IndexError.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque += 'ab'\n",
      "     |      >>> deque.pop()\n",
      "     |      'b'\n",
      "     |      >>> deque.pop()\n",
      "     |      'a'\n",
      "     |      >>> deque.pop()\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      IndexError: pop from an empty deque\n",
      "     |      \n",
      "     |      :return: value at back of deque\n",
      "     |      :raises IndexError: if deque is empty\n",
      "     |  \n",
      "     |  popleft(self)\n",
      "     |      Remove and return value at front of deque.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque += 'ab'\n",
      "     |      >>> deque.popleft()\n",
      "     |      'a'\n",
      "     |      >>> deque.popleft()\n",
      "     |      'b'\n",
      "     |      >>> deque.popleft()\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      IndexError: pop from an empty deque\n",
      "     |      \n",
      "     |      :return: value at front of deque\n",
      "     |      :raises IndexError: if deque is empty\n",
      "     |  \n",
      "     |  remove(self, value)\n",
      "     |      Remove first occurrence of `value` in deque.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque += 'aab'\n",
      "     |      >>> deque.remove('a')\n",
      "     |      >>> list(deque)\n",
      "     |      ['a', 'b']\n",
      "     |      >>> deque.remove('b')\n",
      "     |      >>> list(deque)\n",
      "     |      ['a']\n",
      "     |      >>> deque.remove('c')\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      ValueError: deque.remove(value): value not in deque\n",
      "     |      \n",
      "     |      :param value: value to remove\n",
      "     |      :raises ValueError: if value not in deque\n",
      "     |  \n",
      "     |  reverse(self)\n",
      "     |      Reverse deque in place.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque += 'abc'\n",
      "     |      >>> deque.reverse()\n",
      "     |      >>> list(deque)\n",
      "     |      ['c', 'b', 'a']\n",
      "     |  \n",
      "     |  rotate(self, steps=1)\n",
      "     |      Rotate deque right by `steps`.\n",
      "     |      \n",
      "     |      If steps is negative then rotate left.\n",
      "     |      \n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque += range(5)\n",
      "     |      >>> deque.rotate(2)\n",
      "     |      >>> list(deque)\n",
      "     |      [3, 4, 0, 1, 2]\n",
      "     |      >>> deque.rotate(-1)\n",
      "     |      >>> list(deque)\n",
      "     |      [4, 0, 1, 2, 3]\n",
      "     |      \n",
      "     |      :param int steps: number of steps to rotate (default 1)\n",
      "     |  \n",
      "     |  transact(self)\n",
      "     |      Context manager to perform a transaction by locking the deque.\n",
      "     |      \n",
      "     |      While the deque is locked, no other write operation is permitted.\n",
      "     |      Transactions should therefore be as short as possible. Read and write\n",
      "     |      operations performed in a transaction are atomic. Read operations may\n",
      "     |      occur concurrent to a transaction.\n",
      "     |      \n",
      "     |      Transactions may be nested and may not be shared between threads.\n",
      "     |      \n",
      "     |      >>> from diskcache import Deque\n",
      "     |      >>> deque = Deque()\n",
      "     |      >>> deque += range(5)\n",
      "     |      >>> with deque.transact():  # Atomically rotate elements.\n",
      "     |      ...     value = deque.pop()\n",
      "     |      ...     deque.appendleft(value)\n",
      "     |      >>> list(deque)\n",
      "     |      [4, 0, 1, 2, 3]\n",
      "     |      \n",
      "     |      :return: context manager for use in `with` statement\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromcache(cache, iterable=()) from abc.ABCMeta\n",
      "     |      Initialize deque using `cache`.\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> deque = Deque.fromcache(cache, [5, 6, 7, 8])\n",
      "     |      >>> deque.cache is cache\n",
      "     |      True\n",
      "     |      >>> len(deque)\n",
      "     |      4\n",
      "     |      >>> 7 in deque\n",
      "     |      True\n",
      "     |      >>> deque.popleft()\n",
      "     |      5\n",
      "     |      \n",
      "     |      :param Cache cache: cache to use\n",
      "     |      :param iterable: iterable of items\n",
      "     |      :return: initialized Deque\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  cache\n",
      "     |      Cache used by deque.\n",
      "     |  \n",
      "     |  directory\n",
      "     |      Directory path where deque is stored.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Sequence:\n",
      "     |  \n",
      "     |  __contains__(self, value)\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=None)\n",
      "     |      S.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |      \n",
      "     |      Supporting start and stop arguments is optional, but\n",
      "     |      recommended.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.Reversible:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "    \n",
      "    class Disk(builtins.object)\n",
      "     |  Disk(directory, min_file_size=0, pickle_protocol=0)\n",
      "     |  \n",
      "     |  Cache key and value serialization for SQLite database and files.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, directory, min_file_size=0, pickle_protocol=0)\n",
      "     |      Initialize disk instance.\n",
      "     |      \n",
      "     |      :param str directory: directory path\n",
      "     |      :param int min_file_size: minimum size for file use\n",
      "     |      :param int pickle_protocol: pickle protocol for serialization\n",
      "     |  \n",
      "     |  fetch(self, mode, filename, value, read)\n",
      "     |      Convert fields `mode`, `filename`, and `value` from Cache table to\n",
      "     |      value.\n",
      "     |      \n",
      "     |      :param int mode: value mode raw, binary, text, or pickle\n",
      "     |      :param str filename: filename of corresponding value\n",
      "     |      :param value: database value\n",
      "     |      :param bool read: when True, return an open file handle\n",
      "     |      :return: corresponding Python value\n",
      "     |  \n",
      "     |  filename(self, key=UNKNOWN, value=UNKNOWN)\n",
      "     |      Return filename and full-path tuple for file storage.\n",
      "     |      \n",
      "     |      Filename will be a randomly generated 28 character hexadecimal string\n",
      "     |      with \".val\" suffixed. Two levels of sub-directories will be used to\n",
      "     |      reduce the size of directories. On older filesystems, lookups in\n",
      "     |      directories with many files may be slow.\n",
      "     |      \n",
      "     |      The default implementation ignores the `key` and `value` parameters.\n",
      "     |      \n",
      "     |      In some scenarios, for example :meth:`Cache.push\n",
      "     |      <diskcache.Cache.push>`, the `key` or `value` may not be known when the\n",
      "     |      item is stored in the cache.\n",
      "     |      \n",
      "     |      :param key: key for item (default UNKNOWN)\n",
      "     |      :param value: value for item (default UNKNOWN)\n",
      "     |  \n",
      "     |  get(self, key, raw)\n",
      "     |      Convert fields `key` and `raw` from Cache table to key.\n",
      "     |      \n",
      "     |      :param key: database key to convert\n",
      "     |      :param bool raw: flag indicating raw database storage\n",
      "     |      :return: corresponding Python key\n",
      "     |  \n",
      "     |  hash(self, key)\n",
      "     |      Compute portable hash for `key`.\n",
      "     |      \n",
      "     |      :param key: key to hash\n",
      "     |      :return: hash value\n",
      "     |  \n",
      "     |  put(self, key)\n",
      "     |      Convert `key` to fields key and raw for Cache table.\n",
      "     |      \n",
      "     |      :param key: key to convert\n",
      "     |      :return: (database key, raw boolean) pair\n",
      "     |  \n",
      "     |  remove(self, filename)\n",
      "     |      Remove a file given by `filename`.\n",
      "     |      \n",
      "     |      This method is cross-thread and cross-process safe. If an \"error no\n",
      "     |      entry\" occurs, it is suppressed.\n",
      "     |      \n",
      "     |      :param str filename: relative path to file\n",
      "     |  \n",
      "     |  store(self, value, read, key=UNKNOWN)\n",
      "     |      Convert `value` to fields size, mode, filename, and value for Cache\n",
      "     |      table.\n",
      "     |      \n",
      "     |      :param value: value to convert\n",
      "     |      :param bool read: True when value is file-like object\n",
      "     |      :param key: key for item (default UNKNOWN)\n",
      "     |      :return: (size, mode, filename, value) tuple for Cache table\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class EmptyDirWarning(builtins.UserWarning)\n",
      "     |  Warning used by Cache.check for empty directories.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EmptyDirWarning\n",
      "     |      builtins.UserWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class FanoutCache(builtins.object)\n",
      "     |  FanoutCache(directory=None, shards=8, timeout=0.01, disk=<class 'diskcache.core.Disk'>, **settings)\n",
      "     |  \n",
      "     |  Cache that shards keys and values.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      Return `True` if `key` matching item is found in cache.\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :return: True if key is found\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Delete corresponding item for `key` from cache.\n",
      "     |      \n",
      "     |      Calls :func:`FanoutCache.delete` internally with `retry` set to `True`.\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *exception)\n",
      "     |  \n",
      "     |  __getattr__(self, name)\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Return corresponding value for `key` from cache.\n",
      "     |      \n",
      "     |      Calls :func:`FanoutCache.get` internally with `retry` set to `True`.\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :return: value for item\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, directory=None, shards=8, timeout=0.01, disk=<class 'diskcache.core.Disk'>, **settings)\n",
      "     |      Initialize cache instance.\n",
      "     |      \n",
      "     |      :param str directory: cache directory\n",
      "     |      :param int shards: number of shards to distribute writes\n",
      "     |      :param float timeout: SQLite connection timeout\n",
      "     |      :param disk: `Disk` instance for serialization\n",
      "     |      :param settings: any of `DEFAULT_SETTINGS`\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterate keys in cache including expired items.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Count of items in cache including expired items.\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverse iterate keys in cache including expired items.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Set `key` and `value` item in cache.\n",
      "     |      \n",
      "     |      Calls :func:`FanoutCache.set` internally with `retry` set to `True`.\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param value: value for item\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  add(self, key, value, expire=None, read=False, tag=None, retry=False)\n",
      "     |      Add `key` and `value` item to cache.\n",
      "     |      \n",
      "     |      Similar to `set`, but only add to cache if key not present.\n",
      "     |      \n",
      "     |      This operation is atomic. Only one concurrent add operation for given\n",
      "     |      key from separate threads or processes will succeed.\n",
      "     |      \n",
      "     |      When `read` is `True`, `value` should be a file-like object opened\n",
      "     |      for reading in binary mode.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param value: value for item\n",
      "     |      :param float expire: seconds until the key expires\n",
      "     |          (default None, no expiry)\n",
      "     |      :param bool read: read value as bytes from file (default False)\n",
      "     |      :param str tag: text to associate with key (default None)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if item was added\n",
      "     |  \n",
      "     |  cache(self, name)\n",
      "     |      Return Cache with given `name` in subdirectory.\n",
      "     |      \n",
      "     |      >>> fanout_cache = FanoutCache()\n",
      "     |      >>> cache = fanout_cache.cache('test')\n",
      "     |      >>> cache.set('abc', 123)\n",
      "     |      True\n",
      "     |      >>> cache.get('abc')\n",
      "     |      123\n",
      "     |      >>> len(cache)\n",
      "     |      1\n",
      "     |      >>> cache.delete('abc')\n",
      "     |      True\n",
      "     |      \n",
      "     |      :param str name: subdirectory name for Cache\n",
      "     |      :return: Cache with given name\n",
      "     |  \n",
      "     |  check(self, fix=False, retry=False)\n",
      "     |      Check database and file system consistency.\n",
      "     |      \n",
      "     |      Intended for use in testing and post-mortem error analysis.\n",
      "     |      \n",
      "     |      While checking the cache table for consistency, a writer lock is held\n",
      "     |      on the database. The lock blocks other cache clients from writing to\n",
      "     |      the database. For caches with many file references, the lock may be\n",
      "     |      held for a long time. For example, local benchmarking shows that a\n",
      "     |      cache with 1,000 file references takes ~60ms to check.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param bool fix: correct inconsistencies\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: list of warnings\n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  clear(self, retry=False)\n",
      "     |      Remove all items from cache.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of items removed\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close database connection.\n",
      "     |  \n",
      "     |  create_tag_index(self)\n",
      "     |      Create tag index on cache database.\n",
      "     |      \n",
      "     |      Better to initialize cache with `tag_index=True` than use this.\n",
      "     |      \n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  cull(self, retry=False)\n",
      "     |      Cull items from cache until volume is less than size limit.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of items removed\n",
      "     |  \n",
      "     |  decr(self, key, delta=1, default=0, retry=False)\n",
      "     |      Decrement value by delta for item with key.\n",
      "     |      \n",
      "     |      If key is missing and default is None then raise KeyError. Else if key\n",
      "     |      is missing and default is not None then use default for value.\n",
      "     |      \n",
      "     |      Operation is atomic. All concurrent decrement operations will be\n",
      "     |      counted individually.\n",
      "     |      \n",
      "     |      Unlike Memcached, negative values are supported. Value may be\n",
      "     |      decremented below zero.\n",
      "     |      \n",
      "     |      Assumes value may be stored in a SQLite column. Most builds that target\n",
      "     |      machines with 64-bit pointer widths will support 64-bit signed\n",
      "     |      integers.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param int delta: amount to decrement (default 1)\n",
      "     |      :param int default: value if key is missing (default 0)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: new value for item on success else None\n",
      "     |      :raises KeyError: if key is not found and default is None\n",
      "     |  \n",
      "     |  delete(self, key, retry=False)\n",
      "     |      Delete corresponding item for `key` from cache.\n",
      "     |      \n",
      "     |      Missing keys are ignored.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if item was deleted\n",
      "     |  \n",
      "     |  deque(self, name)\n",
      "     |      Return Deque with given `name` in subdirectory.\n",
      "     |      \n",
      "     |      >>> cache = FanoutCache()\n",
      "     |      >>> deque = cache.deque('test')\n",
      "     |      >>> deque.extend('abc')\n",
      "     |      >>> deque.popleft()\n",
      "     |      'a'\n",
      "     |      >>> deque.pop()\n",
      "     |      'c'\n",
      "     |      >>> len(deque)\n",
      "     |      1\n",
      "     |      \n",
      "     |      :param str name: subdirectory name for Deque\n",
      "     |      :return: Deque with given name\n",
      "     |  \n",
      "     |  drop_tag_index(self)\n",
      "     |      Drop tag index on cache database.\n",
      "     |      \n",
      "     |      :raises Timeout: if database timeout occurs\n",
      "     |  \n",
      "     |  evict(self, tag, retry=False)\n",
      "     |      Remove items with matching `tag` from cache.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param str tag: tag identifying items\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of items removed\n",
      "     |  \n",
      "     |  expire(self, retry=False)\n",
      "     |      Remove expired items from cache.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: count of items removed\n",
      "     |  \n",
      "     |  get(self, key, default=None, read=False, expire_time=False, tag=False, retry=False)\n",
      "     |      Retrieve value from cache. If `key` is missing, return `default`.\n",
      "     |      \n",
      "     |      If database timeout occurs then returns `default` unless `retry` is set\n",
      "     |      to `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param default: return value if key is missing (default None)\n",
      "     |      :param bool read: if True, return file handle to value\n",
      "     |          (default False)\n",
      "     |      :param float expire_time: if True, return expire_time in tuple\n",
      "     |          (default False)\n",
      "     |      :param tag: if True, return tag in tuple (default False)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: value for item if key is found else default\n",
      "     |  \n",
      "     |  incr(self, key, delta=1, default=0, retry=False)\n",
      "     |      Increment value by delta for item with key.\n",
      "     |      \n",
      "     |      If key is missing and default is None then raise KeyError. Else if key\n",
      "     |      is missing and default is not None then use default for value.\n",
      "     |      \n",
      "     |      Operation is atomic. All concurrent increment operations will be\n",
      "     |      counted individually.\n",
      "     |      \n",
      "     |      Assumes value may be stored in a SQLite column. Most builds that target\n",
      "     |      machines with 64-bit pointer widths will support 64-bit signed\n",
      "     |      integers.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param int delta: amount to increment (default 1)\n",
      "     |      :param int default: value if key is missing (default 0)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: new value for item on success else None\n",
      "     |      :raises KeyError: if key is not found and default is None\n",
      "     |  \n",
      "     |  index(self, name)\n",
      "     |      Return Index with given `name` in subdirectory.\n",
      "     |      \n",
      "     |      >>> cache = FanoutCache()\n",
      "     |      >>> index = cache.index('test')\n",
      "     |      >>> index['abc'] = 123\n",
      "     |      >>> index['def'] = 456\n",
      "     |      >>> index['ghi'] = 789\n",
      "     |      >>> index.popitem()\n",
      "     |      ('ghi', 789)\n",
      "     |      >>> del index['abc']\n",
      "     |      >>> len(index)\n",
      "     |      1\n",
      "     |      >>> index['def']\n",
      "     |      456\n",
      "     |      \n",
      "     |      :param str name: subdirectory name for Index\n",
      "     |      :return: Index with given name\n",
      "     |  \n",
      "     |  memoize(self, name=None, typed=False, expire=None, tag=None)\n",
      "     |      Memoizing cache decorator.\n",
      "     |      \n",
      "     |      Decorator to wrap callable with memoizing function using cache.\n",
      "     |      Repeated calls with the same arguments will lookup result in cache and\n",
      "     |      avoid function evaluation.\n",
      "     |      \n",
      "     |      If name is set to None (default), the callable name will be determined\n",
      "     |      automatically.\n",
      "     |      \n",
      "     |      When expire is set to zero, function results will not be set in the\n",
      "     |      cache. Cache lookups still occur, however. Read\n",
      "     |      :doc:`case-study-landing-page-caching` for example usage.\n",
      "     |      \n",
      "     |      If typed is set to True, function arguments of different types will be\n",
      "     |      cached separately. For example, f(3) and f(3.0) will be treated as\n",
      "     |      distinct calls with distinct results.\n",
      "     |      \n",
      "     |      The original underlying function is accessible through the __wrapped__\n",
      "     |      attribute. This is useful for introspection, for bypassing the cache,\n",
      "     |      or for rewrapping the function with a different cache.\n",
      "     |      \n",
      "     |      >>> from diskcache import Cache\n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> @cache.memoize(expire=1, tag='fib')\n",
      "     |      ... def fibonacci(number):\n",
      "     |      ...     if number == 0:\n",
      "     |      ...         return 0\n",
      "     |      ...     elif number == 1:\n",
      "     |      ...         return 1\n",
      "     |      ...     else:\n",
      "     |      ...         return fibonacci(number - 1) + fibonacci(number - 2)\n",
      "     |      >>> print(fibonacci(100))\n",
      "     |      354224848179261915075\n",
      "     |      \n",
      "     |      An additional `__cache_key__` attribute can be used to generate the\n",
      "     |      cache key used for the given arguments.\n",
      "     |      \n",
      "     |      >>> key = fibonacci.__cache_key__(100)\n",
      "     |      >>> print(cache[key])\n",
      "     |      354224848179261915075\n",
      "     |      \n",
      "     |      Remember to call memoize when decorating a callable. If you forget,\n",
      "     |      then a TypeError will occur. Note the lack of parenthenses after\n",
      "     |      memoize below:\n",
      "     |      \n",
      "     |      >>> @cache.memoize\n",
      "     |      ... def test():\n",
      "     |      ...     pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      TypeError: name cannot be callable\n",
      "     |      \n",
      "     |      :param cache: cache to store callable arguments and return values\n",
      "     |      :param str name: name given for callable (default None, automatic)\n",
      "     |      :param bool typed: cache different types separately (default False)\n",
      "     |      :param float expire: seconds until arguments expire\n",
      "     |          (default None, no expiry)\n",
      "     |      :param str tag: text to associate with arguments (default None)\n",
      "     |      :return: callable decorator\n",
      "     |  \n",
      "     |  pop(self, key, default=None, expire_time=False, tag=False, retry=False)\n",
      "     |      Remove corresponding item for `key` from cache and return value.\n",
      "     |      \n",
      "     |      If `key` is missing, return `default`.\n",
      "     |      \n",
      "     |      Operation is atomic. Concurrent operations will be serialized.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param default: return value if key is missing (default None)\n",
      "     |      :param float expire_time: if True, return expire_time in tuple\n",
      "     |          (default False)\n",
      "     |      :param tag: if True, return tag in tuple (default False)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: value for item if key is found else default\n",
      "     |  \n",
      "     |  read(self, key)\n",
      "     |      Return file handle corresponding to `key` from cache.\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :return: file open for reading in binary mode\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |  \n",
      "     |  reset(self, key, value=ENOVAL)\n",
      "     |      Reset `key` and `value` item from Settings table.\n",
      "     |      \n",
      "     |      If `value` is not given, it is reloaded from the Settings\n",
      "     |      table. Otherwise, the Settings table is updated.\n",
      "     |      \n",
      "     |      Settings attributes on cache objects are lazy-loaded and\n",
      "     |      read-only. Use `reset` to update the value.\n",
      "     |      \n",
      "     |      Settings with the ``sqlite_`` prefix correspond to SQLite\n",
      "     |      pragmas. Updating the value will execute the corresponding PRAGMA\n",
      "     |      statement.\n",
      "     |      \n",
      "     |      :param str key: Settings key for item\n",
      "     |      :param value: value for item (optional)\n",
      "     |      :return: updated value for item\n",
      "     |  \n",
      "     |  set(self, key, value, expire=None, read=False, tag=None, retry=False)\n",
      "     |      Set `key` and `value` item in cache.\n",
      "     |      \n",
      "     |      When `read` is `True`, `value` should be a file-like object opened\n",
      "     |      for reading in binary mode.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param value: value for item\n",
      "     |      :param float expire: seconds until the key expires\n",
      "     |          (default None, no expiry)\n",
      "     |      :param bool read: read value as raw bytes from file (default False)\n",
      "     |      :param str tag: text to associate with key (default None)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if item was set\n",
      "     |  \n",
      "     |  stats(self, enable=True, reset=False)\n",
      "     |      Return cache statistics hits and misses.\n",
      "     |      \n",
      "     |      :param bool enable: enable collecting statistics (default True)\n",
      "     |      :param bool reset: reset hits and misses to 0 (default False)\n",
      "     |      :return: (hits, misses)\n",
      "     |  \n",
      "     |  touch(self, key, expire=None, retry=False)\n",
      "     |      Touch `key` in cache and update `expire` time.\n",
      "     |      \n",
      "     |      If database timeout occurs then fails silently unless `retry` is set to\n",
      "     |      `True` (default `False`).\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param float expire: seconds until the key expires\n",
      "     |          (default None, no expiry)\n",
      "     |      :param bool retry: retry if database timeout occurs (default False)\n",
      "     |      :return: True if key was touched\n",
      "     |  \n",
      "     |  volume(self)\n",
      "     |      Return estimated total size of cache on disk.\n",
      "     |      \n",
      "     |      :return: size in bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  directory\n",
      "     |      Cache directory.\n",
      "    \n",
      "    class Index(collections.abc.MutableMapping)\n",
      "     |  Index(*args, **kwargs)\n",
      "     |  \n",
      "     |  Persistent mutable mapping with insertion order iteration.\n",
      "     |  \n",
      "     |  Items are serialized to disk. Index may be initialized from directory path\n",
      "     |  where items are stored.\n",
      "     |  \n",
      "     |  Hashing protocol is not used. Keys are looked up by their serialized\n",
      "     |  format. See ``diskcache.Disk`` for details.\n",
      "     |  \n",
      "     |  >>> index = Index()\n",
      "     |  >>> index.update([('a', 1), ('b', 2), ('c', 3)])\n",
      "     |  >>> index['a']\n",
      "     |  1\n",
      "     |  >>> list(index)\n",
      "     |  ['a', 'b', 'c']\n",
      "     |  >>> len(index)\n",
      "     |  3\n",
      "     |  >>> del index['b']\n",
      "     |  >>> index.popitem()\n",
      "     |  ('c', 3)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Index\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      index.__delitem__(key) <==> del index[key]\n",
      "     |      \n",
      "     |      Delete corresponding item for `key` from index.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update({'a': 1, 'b': 2})\n",
      "     |      >>> del index['a']\n",
      "     |      >>> del index['b']\n",
      "     |      >>> len(index)\n",
      "     |      0\n",
      "     |      >>> del index['c']\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      KeyError: 'c'\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      index.__eq__(other) <==> index == other\n",
      "     |      \n",
      "     |      Compare equality for index and `other`.\n",
      "     |      \n",
      "     |      Comparison to another index or ordered dictionary is\n",
      "     |      order-sensitive. Comparison to all other mappings is order-insensitive.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> pairs = [('a', 1), ('b', 2), ('c', 3)]\n",
      "     |      >>> index.update(pairs)\n",
      "     |      >>> from collections import OrderedDict\n",
      "     |      >>> od = OrderedDict(pairs)\n",
      "     |      >>> index == od\n",
      "     |      True\n",
      "     |      >>> index == {'c': 3, 'b': 2, 'a': 1}\n",
      "     |      True\n",
      "     |      \n",
      "     |      :param other: other mapping in equality comparison\n",
      "     |      :return: True if index equals other\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      index.__getitem__(key) <==> index[key]\n",
      "     |      \n",
      "     |      Return corresponding value for `key` in index.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update({'a': 1, 'b': 2})\n",
      "     |      >>> index['a']\n",
      "     |      1\n",
      "     |      >>> index['b']\n",
      "     |      2\n",
      "     |      >>> index['c']\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      KeyError: 'c'\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :return: value for item in index with given key\n",
      "     |      :raises KeyError: if key is not found\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize index in directory and update items.\n",
      "     |      \n",
      "     |      Optional first argument may be string specifying directory where items\n",
      "     |      are stored. When None or not given, temporary directory is created.\n",
      "     |      \n",
      "     |      >>> index = Index({'a': 1, 'b': 2, 'c': 3})\n",
      "     |      >>> len(index)\n",
      "     |      3\n",
      "     |      >>> directory = index.directory\n",
      "     |      >>> inventory = Index(directory, d=4)\n",
      "     |      >>> inventory['b']\n",
      "     |      2\n",
      "     |      >>> len(inventory)\n",
      "     |      4\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      index.__iter__() <==> iter(index)\n",
      "     |      \n",
      "     |      Return iterator of index keys in insertion order.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      index.__len__() <==> len(index)\n",
      "     |      \n",
      "     |      Return length of index.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      index.__ne__(other) <==> index != other\n",
      "     |      \n",
      "     |      Compare inequality for index and `other`.\n",
      "     |      \n",
      "     |      Comparison to another index or ordered dictionary is\n",
      "     |      order-sensitive. Comparison to all other mappings is order-insensitive.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update([('a', 1), ('b', 2), ('c', 3)])\n",
      "     |      >>> from collections import OrderedDict\n",
      "     |      >>> od = OrderedDict([('c', 3), ('b', 2), ('a', 1)])\n",
      "     |      >>> index != od\n",
      "     |      True\n",
      "     |      >>> index != {'a': 1, 'b': 2}\n",
      "     |      True\n",
      "     |      \n",
      "     |      :param other: other mapping in inequality comparison\n",
      "     |      :return: True if index does not equal other\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      index.__repr__() <==> repr(index)\n",
      "     |      \n",
      "     |      Return string with printable representation of index.\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      index.__reversed__() <==> reversed(index)\n",
      "     |      \n",
      "     |      Return iterator of index keys in reversed insertion order.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update([('a', 1), ('b', 2), ('c', 3)])\n",
      "     |      >>> iterator = reversed(index)\n",
      "     |      >>> next(iterator)\n",
      "     |      'c'\n",
      "     |      >>> list(iterator)\n",
      "     |      ['b', 'a']\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      index.__setitem__(key, value) <==> index[key] = value\n",
      "     |      \n",
      "     |      Set `key` and `value` item in index.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index['a'] = 1\n",
      "     |      >>> index[0] = None\n",
      "     |      >>> len(index)\n",
      "     |      2\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param value: value for item\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      Remove all items from index.\n",
      "     |      \n",
      "     |      >>> index = Index({'a': 0, 'b': 1, 'c': 2})\n",
      "     |      >>> len(index)\n",
      "     |      3\n",
      "     |      >>> index.clear()\n",
      "     |      >>> dict(index)\n",
      "     |      {}\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      Set-like object providing a view of index items.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update({'a': 1, 'b': 2, 'c': 3})\n",
      "     |      >>> items_view = index.items()\n",
      "     |      >>> ('b', 2) in items_view\n",
      "     |      True\n",
      "     |      \n",
      "     |      :return: items view\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      Set-like object providing a view of index keys.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update({'a': 1, 'b': 2, 'c': 3})\n",
      "     |      >>> keys_view = index.keys()\n",
      "     |      >>> 'b' in keys_view\n",
      "     |      True\n",
      "     |      \n",
      "     |      :return: keys view\n",
      "     |  \n",
      "     |  memoize(self, name=None, typed=False)\n",
      "     |      Memoizing cache decorator.\n",
      "     |      \n",
      "     |      Decorator to wrap callable with memoizing function using cache.\n",
      "     |      Repeated calls with the same arguments will lookup result in cache and\n",
      "     |      avoid function evaluation.\n",
      "     |      \n",
      "     |      If name is set to None (default), the callable name will be determined\n",
      "     |      automatically.\n",
      "     |      \n",
      "     |      If typed is set to True, function arguments of different types will be\n",
      "     |      cached separately. For example, f(3) and f(3.0) will be treated as\n",
      "     |      distinct calls with distinct results.\n",
      "     |      \n",
      "     |      The original underlying function is accessible through the __wrapped__\n",
      "     |      attribute. This is useful for introspection, for bypassing the cache,\n",
      "     |      or for rewrapping the function with a different cache.\n",
      "     |      \n",
      "     |      >>> from diskcache import Index\n",
      "     |      >>> mapping = Index()\n",
      "     |      >>> @mapping.memoize()\n",
      "     |      ... def fibonacci(number):\n",
      "     |      ...     if number == 0:\n",
      "     |      ...         return 0\n",
      "     |      ...     elif number == 1:\n",
      "     |      ...         return 1\n",
      "     |      ...     else:\n",
      "     |      ...         return fibonacci(number - 1) + fibonacci(number - 2)\n",
      "     |      >>> print(fibonacci(100))\n",
      "     |      354224848179261915075\n",
      "     |      \n",
      "     |      An additional `__cache_key__` attribute can be used to generate the\n",
      "     |      cache key used for the given arguments.\n",
      "     |      \n",
      "     |      >>> key = fibonacci.__cache_key__(100)\n",
      "     |      >>> print(mapping[key])\n",
      "     |      354224848179261915075\n",
      "     |      \n",
      "     |      Remember to call memoize when decorating a callable. If you forget,\n",
      "     |      then a TypeError will occur. Note the lack of parenthenses after\n",
      "     |      memoize below:\n",
      "     |      \n",
      "     |      >>> @mapping.memoize\n",
      "     |      ... def test():\n",
      "     |      ...     pass\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      TypeError: name cannot be callable\n",
      "     |      \n",
      "     |      :param str name: name given for callable (default None, automatic)\n",
      "     |      :param bool typed: cache different types separately (default False)\n",
      "     |      :return: callable decorator\n",
      "     |  \n",
      "     |  peekitem(self, last=True)\n",
      "     |      Peek at key and value item pair in index based on iteration order.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> for num, letter in enumerate('xyz'):\n",
      "     |      ...     index[letter] = num\n",
      "     |      >>> index.peekitem()\n",
      "     |      ('z', 2)\n",
      "     |      >>> index.peekitem(last=False)\n",
      "     |      ('x', 0)\n",
      "     |      \n",
      "     |      :param bool last: last item in iteration order (default True)\n",
      "     |      :return: key and value item pair\n",
      "     |      :raises KeyError: if cache is empty\n",
      "     |  \n",
      "     |  pop(self, key, default=ENOVAL)\n",
      "     |      Remove corresponding item for `key` from index and return value.\n",
      "     |      \n",
      "     |      If `key` is missing then return `default`. If `default` is `ENOVAL`\n",
      "     |      then raise KeyError.\n",
      "     |      \n",
      "     |      >>> index = Index({'a': 1, 'b': 2})\n",
      "     |      >>> index.pop('a')\n",
      "     |      1\n",
      "     |      >>> index.pop('b')\n",
      "     |      2\n",
      "     |      >>> index.pop('c', default=3)\n",
      "     |      3\n",
      "     |      >>> index.pop('d')\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      KeyError: 'd'\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param default: return value if key is missing (default ENOVAL)\n",
      "     |      :return: value for item if key is found else default\n",
      "     |      :raises KeyError: if key is not found and default is ENOVAL\n",
      "     |  \n",
      "     |  popitem(self, last=True)\n",
      "     |      Remove and return item pair.\n",
      "     |      \n",
      "     |      Item pairs are returned in last-in-first-out (LIFO) order if last is\n",
      "     |      True else first-in-first-out (FIFO) order. LIFO order imitates a stack\n",
      "     |      and FIFO order imitates a queue.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update([('a', 1), ('b', 2), ('c', 3)])\n",
      "     |      >>> index.popitem()\n",
      "     |      ('c', 3)\n",
      "     |      >>> index.popitem(last=False)\n",
      "     |      ('a', 1)\n",
      "     |      >>> index.popitem()\n",
      "     |      ('b', 2)\n",
      "     |      >>> index.popitem()\n",
      "     |      Traceback (most recent call last):\n",
      "     |        ...\n",
      "     |      KeyError: 'dictionary is empty'\n",
      "     |      \n",
      "     |      :param bool last: pop last item pair (default True)\n",
      "     |      :return: key and value item pair\n",
      "     |      :raises KeyError: if index is empty\n",
      "     |  \n",
      "     |  pull(self, prefix=None, default=(None, None), side='front')\n",
      "     |      Pull key and value item pair from `side` of queue in index.\n",
      "     |      \n",
      "     |      When prefix is None, integer keys are used. Otherwise, string keys are\n",
      "     |      used in the format \"prefix-integer\". Integer starts at 500 trillion.\n",
      "     |      \n",
      "     |      If queue is empty, return default.\n",
      "     |      \n",
      "     |      Defaults to pulling key and value item pairs from front of queue. Set\n",
      "     |      side to 'back' to pull from back of queue. Side must be one of 'front'\n",
      "     |      or 'back'.\n",
      "     |      \n",
      "     |      See also `Index.push`.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> for letter in 'abc':\n",
      "     |      ...     print(index.push(letter))\n",
      "     |      500000000000000\n",
      "     |      500000000000001\n",
      "     |      500000000000002\n",
      "     |      >>> key, value = index.pull()\n",
      "     |      >>> print(key)\n",
      "     |      500000000000000\n",
      "     |      >>> value\n",
      "     |      'a'\n",
      "     |      >>> _, value = index.pull(side='back')\n",
      "     |      >>> value\n",
      "     |      'c'\n",
      "     |      >>> index.pull(prefix='fruit')\n",
      "     |      (None, None)\n",
      "     |      \n",
      "     |      :param str prefix: key prefix (default None, key is integer)\n",
      "     |      :param default: value to return if key is missing\n",
      "     |          (default (None, None))\n",
      "     |      :param str side: either 'front' or 'back' (default 'front')\n",
      "     |      :return: key and value item pair or default if queue is empty\n",
      "     |  \n",
      "     |  push(self, value, prefix=None, side='back')\n",
      "     |      Push `value` onto `side` of queue in index identified by `prefix`.\n",
      "     |      \n",
      "     |      When prefix is None, integer keys are used. Otherwise, string keys are\n",
      "     |      used in the format \"prefix-integer\". Integer starts at 500 trillion.\n",
      "     |      \n",
      "     |      Defaults to pushing value on back of queue. Set side to 'front' to push\n",
      "     |      value on front of queue. Side must be one of 'back' or 'front'.\n",
      "     |      \n",
      "     |      See also `Index.pull`.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> print(index.push('apples'))\n",
      "     |      500000000000000\n",
      "     |      >>> print(index.push('beans'))\n",
      "     |      500000000000001\n",
      "     |      >>> print(index.push('cherries', side='front'))\n",
      "     |      499999999999999\n",
      "     |      >>> index[500000000000001]\n",
      "     |      'beans'\n",
      "     |      >>> index.push('dates', prefix='fruit')\n",
      "     |      'fruit-500000000000000'\n",
      "     |      \n",
      "     |      :param value: value for item\n",
      "     |      :param str prefix: key prefix (default None, key is integer)\n",
      "     |      :param str side: either 'back' or 'front' (default 'back')\n",
      "     |      :return: key for item in cache\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      Set and get value for `key` in index using `default`.\n",
      "     |      \n",
      "     |      If `key` is not in index then set corresponding value to `default`. If\n",
      "     |      `key` is in index then ignore `default` and return existing value.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.setdefault('a', 0)\n",
      "     |      0\n",
      "     |      >>> index.setdefault('a', 1)\n",
      "     |      0\n",
      "     |      \n",
      "     |      :param key: key for item\n",
      "     |      :param default: value if key is missing (default None)\n",
      "     |      :return: value for item in index with given key\n",
      "     |  \n",
      "     |  transact(self)\n",
      "     |      Context manager to perform a transaction by locking the index.\n",
      "     |      \n",
      "     |      While the index is locked, no other write operation is permitted.\n",
      "     |      Transactions should therefore be as short as possible. Read and write\n",
      "     |      operations performed in a transaction are atomic. Read operations may\n",
      "     |      occur concurrent to a transaction.\n",
      "     |      \n",
      "     |      Transactions may be nested and may not be shared between threads.\n",
      "     |      \n",
      "     |      >>> from diskcache import Index\n",
      "     |      >>> mapping = Index()\n",
      "     |      >>> with mapping.transact():  # Atomically increment two keys.\n",
      "     |      ...     mapping['total'] = mapping.get('total', 0) + 123.4\n",
      "     |      ...     mapping['count'] = mapping.get('count', 0) + 1\n",
      "     |      >>> with mapping.transact():  # Atomically calculate average.\n",
      "     |      ...     average = mapping['total'] / mapping['count']\n",
      "     |      >>> average\n",
      "     |      123.4\n",
      "     |      \n",
      "     |      :return: context manager for use in `with` statement\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      Set-like object providing a view of index values.\n",
      "     |      \n",
      "     |      >>> index = Index()\n",
      "     |      >>> index.update({'a': 1, 'b': 2, 'c': 3})\n",
      "     |      >>> values_view = index.values()\n",
      "     |      >>> 2 in values_view\n",
      "     |      True\n",
      "     |      \n",
      "     |      :return: values view\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  fromcache(cache, *args, **kwargs) from abc.ABCMeta\n",
      "     |      Initialize index using `cache` and update items.\n",
      "     |      \n",
      "     |      >>> cache = Cache()\n",
      "     |      >>> index = Index.fromcache(cache, {'a': 1, 'b': 2, 'c': 3})\n",
      "     |      >>> index.cache is cache\n",
      "     |      True\n",
      "     |      >>> len(index)\n",
      "     |      3\n",
      "     |      >>> 'b' in index\n",
      "     |      True\n",
      "     |      >>> index['c']\n",
      "     |      3\n",
      "     |      \n",
      "     |      :param Cache cache: cache to use\n",
      "     |      :param args: mapping or sequence of items\n",
      "     |      :param kwargs: mapping of items\n",
      "     |      :return: initialized Index\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  cache\n",
      "     |      Cache used by index.\n",
      "     |  \n",
      "     |  directory\n",
      "     |      Directory path where items are stored.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  update(*args, **kwds)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.Collection:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "    \n",
      "    class JSONDisk(Disk)\n",
      "     |  JSONDisk(directory, compress_level=1, **kwargs)\n",
      "     |  \n",
      "     |  Cache key and value using JSON serialization with zlib compression.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JSONDisk\n",
      "     |      Disk\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, directory, compress_level=1, **kwargs)\n",
      "     |      Initialize JSON disk instance.\n",
      "     |      \n",
      "     |      Keys and values are compressed using the zlib library. The\n",
      "     |      `compress_level` is an integer from 0 to 9 controlling the level of\n",
      "     |      compression; 1 is fastest and produces the least compression, 9 is\n",
      "     |      slowest and produces the most compression, and 0 is no compression.\n",
      "     |      \n",
      "     |      :param str directory: directory path\n",
      "     |      :param int compress_level: zlib compression level (default 1)\n",
      "     |      :param kwargs: super class arguments\n",
      "     |  \n",
      "     |  fetch(self, mode, filename, value, read)\n",
      "     |      Convert fields `mode`, `filename`, and `value` from Cache table to\n",
      "     |      value.\n",
      "     |      \n",
      "     |      :param int mode: value mode raw, binary, text, or pickle\n",
      "     |      :param str filename: filename of corresponding value\n",
      "     |      :param value: database value\n",
      "     |      :param bool read: when True, return an open file handle\n",
      "     |      :return: corresponding Python value\n",
      "     |  \n",
      "     |  get(self, key, raw)\n",
      "     |      Convert fields `key` and `raw` from Cache table to key.\n",
      "     |      \n",
      "     |      :param key: database key to convert\n",
      "     |      :param bool raw: flag indicating raw database storage\n",
      "     |      :return: corresponding Python key\n",
      "     |  \n",
      "     |  put(self, key)\n",
      "     |      Convert `key` to fields key and raw for Cache table.\n",
      "     |      \n",
      "     |      :param key: key to convert\n",
      "     |      :return: (database key, raw boolean) pair\n",
      "     |  \n",
      "     |  store(self, value, read, key=UNKNOWN)\n",
      "     |      Convert `value` to fields size, mode, filename, and value for Cache\n",
      "     |      table.\n",
      "     |      \n",
      "     |      :param value: value to convert\n",
      "     |      :param bool read: True when value is file-like object\n",
      "     |      :param key: key for item (default UNKNOWN)\n",
      "     |      :return: (size, mode, filename, value) tuple for Cache table\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Disk:\n",
      "     |  \n",
      "     |  filename(self, key=UNKNOWN, value=UNKNOWN)\n",
      "     |      Return filename and full-path tuple for file storage.\n",
      "     |      \n",
      "     |      Filename will be a randomly generated 28 character hexadecimal string\n",
      "     |      with \".val\" suffixed. Two levels of sub-directories will be used to\n",
      "     |      reduce the size of directories. On older filesystems, lookups in\n",
      "     |      directories with many files may be slow.\n",
      "     |      \n",
      "     |      The default implementation ignores the `key` and `value` parameters.\n",
      "     |      \n",
      "     |      In some scenarios, for example :meth:`Cache.push\n",
      "     |      <diskcache.Cache.push>`, the `key` or `value` may not be known when the\n",
      "     |      item is stored in the cache.\n",
      "     |      \n",
      "     |      :param key: key for item (default UNKNOWN)\n",
      "     |      :param value: value for item (default UNKNOWN)\n",
      "     |  \n",
      "     |  hash(self, key)\n",
      "     |      Compute portable hash for `key`.\n",
      "     |      \n",
      "     |      :param key: key to hash\n",
      "     |      :return: hash value\n",
      "     |  \n",
      "     |  remove(self, filename)\n",
      "     |      Remove a file given by `filename`.\n",
      "     |      \n",
      "     |      This method is cross-thread and cross-process safe. If an \"error no\n",
      "     |      entry\" occurs, it is suppressed.\n",
      "     |      \n",
      "     |      :param str filename: relative path to file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Disk:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Lock(builtins.object)\n",
      "     |  Lock(cache, key, expire=None, tag=None)\n",
      "     |  \n",
      "     |  Recipe for cross-process and cross-thread lock.\n",
      "     |  \n",
      "     |  >>> import diskcache\n",
      "     |  >>> cache = diskcache.Cache()\n",
      "     |  >>> lock = Lock(cache, 'report-123')\n",
      "     |  >>> lock.acquire()\n",
      "     |  >>> lock.release()\n",
      "     |  >>> with lock:\n",
      "     |  ...     pass\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *exc_info)\n",
      "     |  \n",
      "     |  __init__(self, cache, key, expire=None, tag=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  acquire(self)\n",
      "     |      Acquire lock using spin-lock algorithm.\n",
      "     |  \n",
      "     |  release(self)\n",
      "     |      Release lock by deleting key.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RLock(builtins.object)\n",
      "     |  RLock(cache, key, expire=None, tag=None)\n",
      "     |  \n",
      "     |  Recipe for cross-process and cross-thread re-entrant lock.\n",
      "     |  \n",
      "     |  >>> import diskcache\n",
      "     |  >>> cache = diskcache.Cache()\n",
      "     |  >>> rlock = RLock(cache, 'user-123')\n",
      "     |  >>> rlock.acquire()\n",
      "     |  >>> rlock.acquire()\n",
      "     |  >>> rlock.release()\n",
      "     |  >>> with rlock:\n",
      "     |  ...     pass\n",
      "     |  >>> rlock.release()\n",
      "     |  >>> rlock.release()\n",
      "     |  Traceback (most recent call last):\n",
      "     |    ...\n",
      "     |  AssertionError: cannot release un-acquired lock\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *exc_info)\n",
      "     |  \n",
      "     |  __init__(self, cache, key, expire=None, tag=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  acquire(self)\n",
      "     |      Acquire lock by incrementing count using spin-lock algorithm.\n",
      "     |  \n",
      "     |  release(self)\n",
      "     |      Release lock by decrementing count.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Timeout(builtins.Exception)\n",
      "     |  Database timeout expired.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Timeout\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class UnknownFileWarning(builtins.UserWarning)\n",
      "     |  Warning used by Cache.check for unknown files.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnknownFileWarning\n",
      "     |      builtins.UserWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.UserWarning:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    barrier(cache, lock_factory, name=None, expire=None, tag=None)\n",
      "        Barrier to calling decorated function.\n",
      "        \n",
      "        Supports different kinds of locks: Lock, RLock, BoundedSemaphore.\n",
      "        \n",
      "        >>> import diskcache, time\n",
      "        >>> cache = diskcache.Cache()\n",
      "        >>> @barrier(cache, Lock)\n",
      "        ... def work(num):\n",
      "        ...     print('worker started')\n",
      "        ...     time.sleep(1)\n",
      "        ...     print('worker finished')\n",
      "        >>> import multiprocessing.pool\n",
      "        >>> pool = multiprocessing.pool.ThreadPool(2)\n",
      "        >>> _ = pool.map(work, range(2))\n",
      "        worker started\n",
      "        worker finished\n",
      "        worker started\n",
      "        worker finished\n",
      "        >>> pool.terminate()\n",
      "    \n",
      "    memoize_stampede(cache, expire, name=None, typed=False, tag=None, beta=1)\n",
      "        Memoizing cache decorator with cache stampede protection.\n",
      "        \n",
      "        Cache stampedes are a type of system overload that can occur when parallel\n",
      "        computing systems using memoization come under heavy load. This behaviour\n",
      "        is sometimes also called dog-piling, cache miss storm, cache choking, or\n",
      "        the thundering herd problem.\n",
      "        \n",
      "        The memoization decorator implements cache stampede protection through\n",
      "        early recomputation. Early recomputation of function results will occur\n",
      "        probabilistically before expiration in a background thread of\n",
      "        execution. Early probabilistic recomputation is based on research by\n",
      "        Vattani, A.; Chierichetti, F.; Lowenstein, K. (2015), Optimal Probabilistic\n",
      "        Cache Stampede Prevention, VLDB, pp. 886-897, ISSN 2150-8097\n",
      "        \n",
      "        If name is set to None (default), the callable name will be determined\n",
      "        automatically.\n",
      "        \n",
      "        If typed is set to True, function arguments of different types will be\n",
      "        cached separately. For example, f(3) and f(3.0) will be treated as distinct\n",
      "        calls with distinct results.\n",
      "        \n",
      "        The original underlying function is accessible through the `__wrapped__`\n",
      "        attribute. This is useful for introspection, for bypassing the cache, or\n",
      "        for rewrapping the function with a different cache.\n",
      "        \n",
      "        >>> from diskcache import Cache\n",
      "        >>> cache = Cache()\n",
      "        >>> @memoize_stampede(cache, expire=1)\n",
      "        ... def fib(number):\n",
      "        ...     if number == 0:\n",
      "        ...         return 0\n",
      "        ...     elif number == 1:\n",
      "        ...         return 1\n",
      "        ...     else:\n",
      "        ...         return fib(number - 1) + fib(number - 2)\n",
      "        >>> print(fib(100))\n",
      "        354224848179261915075\n",
      "        \n",
      "        An additional `__cache_key__` attribute can be used to generate the cache\n",
      "        key used for the given arguments.\n",
      "        \n",
      "        >>> key = fib.__cache_key__(100)\n",
      "        >>> del cache[key]\n",
      "        \n",
      "        Remember to call memoize when decorating a callable. If you forget, then a\n",
      "        TypeError will occur.\n",
      "        \n",
      "        :param cache: cache to store callable arguments and return values\n",
      "        :param float expire: seconds until arguments expire\n",
      "        :param str name: name given for callable (default None, automatic)\n",
      "        :param bool typed: cache different types separately (default False)\n",
      "        :param str tag: text to associate with arguments (default None)\n",
      "        :return: callable decorator\n",
      "    \n",
      "    throttle(cache, count, seconds, name=None, expire=None, tag=None, time_func=<built-in function time>, sleep_func=<built-in function sleep>)\n",
      "        Decorator to throttle calls to function.\n",
      "        \n",
      "        >>> import diskcache, time\n",
      "        >>> cache = diskcache.Cache()\n",
      "        >>> count = 0\n",
      "        >>> @throttle(cache, 2, 1)  # 2 calls per 1 second\n",
      "        ... def increment():\n",
      "        ...     global count\n",
      "        ...     count += 1\n",
      "        >>> start = time.time()\n",
      "        >>> while (time.time() - start) <= 2:\n",
      "        ...     increment()\n",
      "        >>> count in (6, 7)  # 6 or 7 calls depending on CPU load\n",
      "        True\n",
      "\n",
      "DATA\n",
      "    DEFAULT_SETTINGS = {'cull_limit': 10, 'disk_min_file_size': 32768, 'di...\n",
      "    ENOVAL = ENOVAL\n",
      "    EVICTION_POLICY = {'least-frequently-used': {'cull': 'SELECT {fields} ...\n",
      "    UNKNOWN = UNKNOWN\n",
      "    __all__ = ['Averager', 'BoundedSemaphore', 'Cache', 'DEFAULT_SETTINGS'...\n",
      "    __build__ = 262400\n",
      "    __copyright__ = 'Copyright 2016-2018 Grant Jenks'\n",
      "    __license__ = 'Apache 2.0'\n",
      "    __title__ = 'diskcache'\n",
      "\n",
      "VERSION\n",
      "    4.1.0\n",
      "\n",
      "AUTHOR\n",
      "    Grant Jenks\n",
      "\n",
      "FILE\n",
      "    /home/dbadmin/anaconda3/lib/python3.7/site-packages/diskcache/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import diskcache\n",
    "help(diskcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.test_database\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = {\"author\": \"Mike\",\n",
    "         \"text\": \"My first blog post!\",\n",
    "         \"tags\": [\"mongodb\", \"python\", \"pymongo\"],\n",
    "         \"date\": datetime.datetime.utcnow()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "post2 = {\"author\": \"Mike2\",\n",
    "         \"text\": \"My first blog post2!\",\n",
    "         \"tags\": [\"mongo2db\", \"pyt2hon\", \"py2mongo\"],\n",
    "         \"date\": datetime.datetime.utcnow()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = db.posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('5edeff9b11c2691c9cac21c1')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_id = posts.insert_one(post2).inserted_id\n",
    "post_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5edefd0a11c2691c9cac21c0'),\n",
      " 'author': 'Mike',\n",
      " 'date': datetime.datetime(2020, 6, 9, 3, 7, 24, 82000),\n",
      " 'tags': ['mongodb', 'python', 'pymongo'],\n",
      " 'text': 'My first blog post!'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(posts.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diskcache as dc\n",
    "cache = dc.Cache('tmp')\n",
    "# cache[b'key'] = b'value'\n",
    "# %timeit cache[b'key'] = b'value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 µs ± 369 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "d = shelve.open('./tmp.shv')  \n",
    "d['key'] = b'value'\n",
    "%timeit d['key'] = b'value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "rating_data_path = './movie_dataset/ratings_rev1.csv'\n",
    "rdf = pd.read_csv(rating_data_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1256677471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      307     3.5  1256677221\n",
       "1       1      481     3.5  1256677456\n",
       "2       1     1091     1.5  1256677471\n",
       "3       1     1257     4.5  1256677460\n",
       "4       1     1449     4.5  1256677264"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>814978800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>818953200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>819558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>819558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1995-12-08</td>\n",
       "      <td>818348400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1          2\n",
       "0  1  1995-10-30  814978800\n",
       "1  2  1995-12-15  818953200\n",
       "2  3  1995-12-22  819558000\n",
       "3  4  1995-12-22  819558000\n",
       "4  5  1995-12-08  818348400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_data_path = './movie_dataset/release_dates.csv'\n",
    "redf = pd.read_csv(release_data_path, delimiter=',', header=None)\n",
    "\n",
    "redf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_index = dict()\n",
    "for i in range(len(redf)):\n",
    "    rel_index[redf[0][i]] = redf[2][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1      307     3.5  1256677221\n",
      "1       1      481     3.5  1256677456\n",
      "2       1     1091     1.5  1256677471\n",
      "3       1     1257     4.5  1256677460\n",
      "4       1     1449     4.5  1256677264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbadmin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1      307     3.5   991634410\n",
      "1       1      481     3.5  1001743328\n",
      "2       1     1091     1.5   936122535\n",
      "3       1     1257     4.5   877240930\n",
      "4       1     1449     4.5  1048615232\n"
     ]
    }
   ],
   "source": [
    "print(rdf.head())\n",
    "for i in range(len(rdf)):\n",
    "    temp_timestamp = (rdf['timestamp'][i] - rel_index[rdf['movieId'][i]])\n",
    "    if temp_timestamp > 0 :\n",
    "        temp_timestamp /= 2\n",
    "        rdf['timestamp'][i] = temp_timestamp + rel_index[rdf['movieId'][i]]\n",
    "\n",
    "print(rdf.head())\n",
    "#     rdf['timestamp'][i] = \n",
    "#     print(rel_index[rdf['movieId'][i]])\n",
    "#     temp_timestamp \n",
    "#     if rel_index[rdf['movieId']] > temp_timestamp:\n",
    "#         = temp_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rating_data_path = './movie_dataset/ratings_enhanced.csv'\n",
    "rdf.to_csv(new_rating_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rdf = pd.read_csv(new_rating_data_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>726591663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>746809260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>615567676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>497804490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>840553249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  userId  movieId  rating  timestamp\n",
       "0           0       1      307     3.5  726591663\n",
       "1           1       1      481     3.5  746809260\n",
       "2           2       1     1091     1.5  615567676\n",
       "3           3       1     1257     4.5  497804490\n",
       "4           4       1     1449     4.5  840553249"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "new_rating_data_path = './sequence_data/synthetic_200000/sequences.pkl'\n",
    "syn_rel_data_path = './sequence_data/synthetic_200000/release_data.pkl'\n",
    "syn_set_data_path = './sequence_data/synthetic_200000/set_sequences_set_16.pkl'\n",
    "\n",
    "with open(new_rating_data_path, 'rb') as f:\n",
    "    synthetic_seq = pickle.load(f)\n",
    "\n",
    "with open(syn_rel_data_path, 'rb') as f :\n",
    "    syn_rel_index = pickle.load(f)\n",
    "\n",
    "with open(syn_set_data_path, 'rb') as f :\n",
    "    synthetic_set_seq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2521,  4530, 24486,    64, 30117, 10380, 10410, 32067, 25913,\n",
       "         1201,     8,   882, 32059,  3356, 12338, 12867,     2, 25156,\n",
       "         1632,  5396, 14604, 21399, 35622,  3451, 35894,  1688, 17286,\n",
       "           51,  1612,  3960,  3614,  1253,    17, 24981,  5595, 11983,\n",
       "        20403,  3591, 32775, 16491,  2710,  4009, 23326, 12759,  1514,\n",
       "         1840, 14266,  5197, 18800,  1073,  4322,  5243,    81,    66,\n",
       "        26333, 25590,  3540, 19300,  1332, 13373, 40561, 37839, 38657,\n",
       "         6786,  6397,  2694,  1994,   675, 24711, 12087,  7653, 18286,\n",
       "        31894,  9172,  1525,  7994,  1067,    80, 19820, 31112,   164,\n",
       "         4065,    42, 37190,  2346,  7037,  1598, 25429,   659,  9564,\n",
       "        14149, 21860, 31759,  1477,  5527, 12453, 12478, 34339,   371,\n",
       "            3, 15809,  3137,   709,   927,  8738,  7304,   143,  7827,\n",
       "          100, 28410, 40038,  8786,  6585,  1250,    59,  3179, 32163,\n",
       "         1364,  8004, 22672,   125, 27443,  4154,    54,  1244, 18202,\n",
       "          392,  8181, 16703,  7483, 16085,  1307, 18336,   769,  1723,\n",
       "            7,   263, 10235,   825,  2029,   105,  7727, 10246, 32809,\n",
       "        22700, 14901,  5101,  8756, 38910,   333,   280,  8823,  8230,\n",
       "         2828,  1222,  2569,  1875,  5003,   133,  1254,   953,   117,\n",
       "          827,  1278, 13177,  6557,  9094,  6515, 19642, 27071,   370,\n",
       "          810,  3423, 34596,  3425,  5668,  1295,    29,  2993,  2110,\n",
       "        15987,     1,   498,   716,  2127,    10,   980, 15335, 21989,\n",
       "         4555,     5,  2432, 27942,  5892,   170,  9361,  7371, 13141,\n",
       "          723,   445, 12738, 15350,    82,  2404,  2443,  1647,  2585,\n",
       "          255,  2446,     9,   158,   742,  1030, 19680, 19375,  1690,\n",
       "         3357,    57,  8911,  3188,  8625, 10381,   163,     4]),\n",
       " array([-932986220, -815209184, -710281809, -690209986, -537633274,\n",
       "        -532030486, -495406981, -462555087, -436673242, -412297648,\n",
       "        -383690911, -320274638, -298378450, -279287241, -258804031,\n",
       "        -245823198, -216259788, -186790011,  -51975807,    8805073,\n",
       "          30126585,   52028230,  131526552,  154831661,  160118595,\n",
       "         171788578,  171830745,  180077108,  240312919,  245048432,\n",
       "         254093284,  263037213,  284321776,  356879709,  383422582,\n",
       "         399739426,  432540724,  449215180,  466456411,  482784874,\n",
       "         489034312,  493835984,  497709973,  506700987,  529363837,\n",
       "         545112184,  545375345,  546974413,  547847814,  553170798,\n",
       "         575108904,  602546931,  607678429,  608815495,  610612425,\n",
       "         614059225,  624140493,  629546514,  644444616,  655945825,\n",
       "         682809509,  691652018,  693629935,  715708644,  719868955,\n",
       "         720616230,  721163461,  724185709,  724488501,  726312263,\n",
       "         736372646,  739025380,  752389869,  754025972,  766278785,\n",
       "         782824546,  789311807,  795904886,  800698012,  819466598,\n",
       "         819521421,  820783186,  832485315,  841367717,  879091591,\n",
       "         910512175,  921554878,  952996515,  956089690,  963539350,\n",
       "         965215829,  967518302,  971183246,  976287986,  982019145,\n",
       "         983374623,  990988788,  997878177,  999100214, 1001699802,\n",
       "        1018504164, 1026629663, 1032872716, 1045266560, 1049557215,\n",
       "        1060044606, 1076465417, 1104788028, 1105346383, 1108147868,\n",
       "        1109320729, 1114680542, 1133537581, 1142732430, 1143762374,\n",
       "        1146036303, 1149617157, 1154320252, 1155220188, 1158656429,\n",
       "        1160365314, 1162979247, 1168653698, 1168843542, 1170649855,\n",
       "        1182682897, 1192005833, 1194022046, 1195391718, 1199392893,\n",
       "        1203099333, 1205077981, 1207445586, 1209485951, 1211402987,\n",
       "        1212463220, 1219896857, 1223513201, 1225633228, 1230139315,\n",
       "        1231194996, 1244002101, 1248069879, 1249903818, 1252700571,\n",
       "        1257895800, 1268263442, 1271707633, 1273777795, 1281756824,\n",
       "        1282064264, 1288525031, 1289909558, 1296977022, 1300987538,\n",
       "        1304256623, 1304470793, 1304846106, 1316242166, 1322502852,\n",
       "        1332227315, 1336481670, 1336708949, 1336978224, 1339089875,\n",
       "        1339380903, 1341333340, 1342608841, 1342849018, 1357804436,\n",
       "        1369231977, 1369300283, 1371138113, 1374001628, 1379111227,\n",
       "        1383018258, 1385530423, 1389966827, 1392680560, 1399136549,\n",
       "        1400776739, 1402943870, 1403716311, 1409669381, 1417153901,\n",
       "        1424327686, 1425815984, 1426415986, 1426638292, 1432148942,\n",
       "        1436101460, 1437469031, 1439828390, 1440199165, 1440652501,\n",
       "        1441597534, 1443670425, 1444039735, 1444862498, 1449923973,\n",
       "        1451813622, 1454500645, 1455926020, 1457664418, 1464185213,\n",
       "        1464821714, 1466026723, 1466839120, 1472849816, 1478271256,\n",
       "        1486109078, 1488208975, 1490134842, 1492775182, 1494053509,\n",
       "        1494101817, 1497534874, 1502461735, 1509215759, 1510375203,\n",
       "        1512751813, 1513325550, 1524129817, 1534185075]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_seq[0][0], synthetic_seq[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-245823198,\n",
       " frozenset({8,\n",
       "            64,\n",
       "            882,\n",
       "            1201,\n",
       "            2521,\n",
       "            3356,\n",
       "            4530,\n",
       "            10380,\n",
       "            10410,\n",
       "            12338,\n",
       "            12867,\n",
       "            24486,\n",
       "            25913,\n",
       "            30117,\n",
       "            32059,\n",
       "            32067}))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_set_seq[0][0].max_timestamp, synthetic_set_seq[0][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-932986220"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_rel_index[2521]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "new_rating_data_path = './sequence_data/not_real_world/sequences.pkl'\n",
    "old_rating_data_path = './sequence_data/real_world/sequences.pkl'\n",
    "# syn_rel_data_path = './sequence_data/synthetic_200000/release_data.pkl'\n",
    "# syn_set_data_path = './sequence_data/synthetic_200000/set_sequences_set_16.pkl'\n",
    "\n",
    "with open(new_rating_data_path, 'rb') as f:\n",
    "    new_seq = pickle.load(f)\n",
    "\n",
    "with open(old_rating_data_path, 'rb') as f:\n",
    "    old_seq = pickle.load(f)\n",
    "# with open(syn_rel_data_path, 'rb') as f :\n",
    "#     syn_rel_index = pickle.load(f)\n",
    "\n",
    "# with open(syn_set_data_path, 'rb') as f :\n",
    "#     synthetic_set_seq = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250703, 250703)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_seq), len(old_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[      960,      3171,      1221,      1321,      1985,      2024,\n",
       "               640,       828,      1645,      1825,      2028],\n",
       "        [105181703, 299885003, 550919303, 656154503, 769252205, 815821805,\n",
       "         886281005, 891724205, 911077805, 918551405, 923173805]]),\n",
       " array([[      960,       640,      1645],\n",
       "        [945141407, 945141610, 945141611]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_seq[3], old_seq[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_length_list = list(map(lambda x: len(new_seq[x][0]), new_seq.keys()))\n",
    "old_length_list = list(map(lambda x: len(old_seq[x][0]), old_seq.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(new_length_list) != np.array(old_length_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_array = np.array([1,2,3])\n",
    "d2_array = np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "result = np.where(t_array > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
